{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an continuation of the 1st attempt at creating a reasonably good model for the Heart Disease dataset. I will try to address the following issue that I found in the 1st attempt:\n",
    "1. The labels are unbalanced: the number of people who don't have heart diease is 10.7 times the number of people who do.\n",
    "2. Some features are also unbalanced. For example, features like \"AlcoholDrinking\", \"Stroke\", \"Race\", \"KidneyDiease\" all have one value that has more count than all other values combined.\n",
    "3. All the classifiers trained in the 1st attempt has very low precision & recall for the \"yes\" label. Most classifiers have a high overall accuracy because they predict most instances to be \"no\". This is not a good result for this project as we want to have a high recall (preferably also high precision) for the \"yes\" label).                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "category_cols = [col for col in data.columns if data[col].dtype == 'object']\n",
    "data = pd.get_dummies(data=data, columns=category_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['HeartDisease_Yes'], axis=1), data['HeartDisease_Yes'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='HeartDisease_Yes'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind='pie', autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# this is the exact same as feature scaling in the 1st exploration\n",
    "std_scaler = StandardScaler()\n",
    "X_train = std_scaler.fit_transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21781\n",
       "1    21781\n",
       "Name: HeartDisease_Yes, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "y_train_rus.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    234055\n",
       "1    234055\n",
       "Name: HeartDisease_Yes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "y_train_ros.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    234055\n",
       "1    234055\n",
       "Name: HeartDisease_Yes, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22109\n",
       "1     2111\n",
       "Name: HeartDisease_Yes, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# TomekLinks runtime is O(n^2), so we will use a smaller dataset in this case\n",
    "\n",
    "size = 25000\n",
    "tl = TomekLinks()\n",
    "X_train_tl, y_train_tl = tl.fit_resample(X_train[:size], y_train[:size])\n",
    "y_train_tl.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Combining SMOTE and Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22662\n",
       "1    22662\n",
       "Name: HeartDisease_Yes, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# again, we will use a smaller dataset\n",
    "\n",
    "smote_tl = SMOTETomek(random_state=42)\n",
    "X_train_smote_tl, y_train_smote_tl = smote_tl.fit_resample(X_train[:size], y_train[:size])\n",
    "y_train_smote_tl.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train some classifiers on the balanced data.\n",
    "<br>\n",
    "**NOTE**: in the code below, I show my initial mistake of oversampling the data and then performing cross validation on top of it. The problem with this is that with oversampling, we are duplicating the entries in the minority class several times. When we separate the training data into multiple folds, these duplicated minority class entires will be included in different folds. During model training, the classifier will see the duplicated entries several times in the training folds, thus it will overfit/\"memorize\" these duplicated entries' labels. During validation, the classifier will likely encounter these duplicated entries again and predict their labels perfectly.\n",
    "<br>\n",
    "**Overall, cross validation before oversampling inflates the scores of the classifiers, as we will see below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def cross_validate_model_diff_data_same_model(model, Xs, ys, sampling_methods_names, cv=3, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']):\n",
    "    scores_lst = []\n",
    "    i = 0\n",
    "    for X, y in zip(Xs, ys):\n",
    "        scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "        scores_lst.append({k: round(v.mean(), 2) for k, v in scores.items()})\n",
    "        print(f'Finished cross-validation for {sampling_methods_names[i]}')\n",
    "        i += 1\n",
    "    return pd.DataFrame(scores_lst, index=sampling_methods_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cross-validation for RUS\n",
      "Finished cross-validation for ROS\n",
      "Finished cross-validation for SMOTE\n",
      "Finished cross-validation for TomekLinks\n",
      "Finished cross-validation for SMOTETomek\n",
      "            fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "RUS             0.44        0.08           0.76            0.75         0.78   \n",
      "ROS             4.28        0.51           0.76            0.76         0.78   \n",
      "SMOTE           3.65        0.47           0.77            0.76         0.79   \n",
      "TomekLinks      0.19        0.03           0.91            0.56         0.12   \n",
      "SMOTETomek      0.35        0.05           0.78            0.76         0.80   \n",
      "\n",
      "            test_f1  test_roc_auc  \n",
      "RUS            0.77          0.84  \n",
      "ROS            0.77          0.84  \n",
      "SMOTE          0.77          0.84  \n",
      "TomekLinks     0.20          0.85  \n",
      "SMOTETomek     0.78          0.85  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Xs = [X_train_rus, X_train_ros, X_train_smote, X_train_tl, X_train_smote_tl]\n",
    "ys = [y_train_rus, y_train_ros, y_train_smote, y_train_tl, y_train_smote_tl]\n",
    "\n",
    "lr_score_table = cross_validate_model_diff_data_same_model(LogisticRegression(), Xs, ys, ['RUS', 'ROS', 'SMOTE', 'TomekLinks', 'SMOTETomek'])\n",
    "print(lr_score_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As expected, the scores in \"test_recall\" column looks a lot better compared to the \"test_recall\" column in the 1st attempt without balancing data (For Logistic Regression, the score is 0.11!).\n",
    "* Interestingly, the \"test_precision\" score has also improved.\n",
    "Let's try the balanced datasets on Decision Tree Classifier and Random Forest Classifier with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cross-validation for RUS\n",
      "Finished cross-validation for ROS\n",
      "Finished cross-validation for SMOTE\n",
      "Finished cross-validation for TomekLinks\n",
      "Finished cross-validation for SMOTETomek\n",
      "            fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "RUS             0.54        0.10           0.67            0.67         0.67   \n",
      "ROS             7.17        0.54           0.95            0.91         1.00   \n",
      "SMOTE           7.02        0.53           0.89            0.89         0.88   \n",
      "TomekLinks      0.23        0.04           0.87            0.26         0.28   \n",
      "SMOTETomek      0.37        0.05           0.91            0.91         0.91   \n",
      "\n",
      "            test_f1  test_roc_auc  \n",
      "RUS            0.67          0.67  \n",
      "ROS            0.95          0.95  \n",
      "SMOTE          0.88          0.89  \n",
      "TomekLinks     0.27          0.60  \n",
      "SMOTETomek     0.91          0.91  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dt_score_table = cross_validate_model_diff_data_same_model(DecisionTreeClassifier(), Xs, ys, ['RUS', 'ROS', 'SMOTE', 'TomekLinks', 'SMOTETomek'])\n",
    "print(dt_score_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cross-validation for RUS\n",
      "Finished cross-validation for ROS\n",
      "Finished cross-validation for SMOTE\n",
      "Finished cross-validation for TomekLinks\n",
      "Finished cross-validation for SMOTETomek\n",
      "            fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "RUS             4.97        1.15           0.74            0.73         0.77   \n",
      "ROS           103.23       22.23           0.96            0.93         1.00   \n",
      "SMOTE         123.21       20.68           0.92            0.93         0.92   \n",
      "TomekLinks      4.12        0.53           0.91            0.54         0.10   \n",
      "SMOTETomek      6.33        1.23           0.95            0.96         0.94   \n",
      "\n",
      "            test_f1  test_roc_auc  \n",
      "RUS            0.75          0.81  \n",
      "ROS            0.96          1.00  \n",
      "SMOTE          0.92          0.97  \n",
      "TomekLinks     0.18          0.82  \n",
      "SMOTETomek     0.95          0.99  \n"
     ]
    }
   ],
   "source": [
    "rf_score_table = cross_validate_model_diff_data_same_model(RandomForestClassifier(), Xs, ys, ['RUS', 'ROS', 'SMOTE', 'TomekLinks', 'SMOTETomek'])\n",
    "print(rf_score_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Random Oversampling for Decision Tree Classifier and RandomForest Classifier has a recall of 1 on cross validation. This might be because the function \"cross_validate_model_diff_data_same_model\" rounds each score to 2 decimal places (it's not actually 1). Nonetheless, this result looks very good.\n",
    "* Notice that the oversampled datasets here (ROS, SMOTE) has higher precison and recall scores than those of undersampled datasets (RUS, Tomek Links). SMOTETomek's scores sits between the two categories. This makes sense because this dataset doesn't have a lot of entries (319795) so undersampling has a higher chance of removing useful entries. And as mentioned, the classfiers trained on the k - 1 folds of the oversampled data are likely to overfit the test fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform cross validation the correct way on oversampled data. The key is that, for each fold, only oversample the minority class from the k - 1 folds and validate on the remaining fold which is not oversampled. In other words, we should perform oversampling during cross validation, and not before cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "def cross_validate_diff_models_diff_data(models, resampling_methods, reduced_size=50000, cv=3, scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']):\n",
    "    scores_lst = []\n",
    "    for m in models:\n",
    "        for r in resampling_methods:\n",
    "            pipe = make_pipeline(r, m)\n",
    "            print(f'now cross-validating {m.__class__.__name__} with {r.__class__.__name__}')\n",
    "            if isinstance(r, TomekLinks) or isinstance(r, SMOTETomek):  # since TomekLinks and SMOTETomek are slow, we will use a smaller dataset\n",
    "                scores = cross_validate(pipe, X_train[:reduced_size], y_train[:reduced_size], cv=cv, scoring=scoring)\n",
    "            else:\n",
    "                scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring)\n",
    "            scores_lst.append({k: round(v.mean(), 2) for k, v in scores.items()})\n",
    "            print(f'Finished cross-validation for {r.__class__.__name__} with {m.__class__.__name__}')\n",
    "    index = pd.MultiIndex.from_product([[m.__class__.__name__ for m in models], [r.__class__.__name__ for r in resampling_methods]], names=['model', 'resampling_method'])\n",
    "    return pd.DataFrame(scores_lst, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell might take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now cross-validating LogisticRegression with RandomUnderSampler\n",
      "Finished cross-validation for RandomUnderSampler with LogisticRegression\n",
      "now cross-validating LogisticRegression with RandomOverSampler\n",
      "Finished cross-validation for RandomOverSampler with LogisticRegression\n",
      "now cross-validating LogisticRegression with SMOTE\n",
      "Finished cross-validation for SMOTE with LogisticRegression\n",
      "now cross-validating LogisticRegression with TomekLinks\n",
      "Finished cross-validation for TomekLinks with LogisticRegression\n",
      "now cross-validating LogisticRegression with SMOTETomek\n",
      "Finished cross-validation for SMOTETomek with LogisticRegression\n",
      "now cross-validating DecisionTreeClassifier with RandomUnderSampler\n",
      "Finished cross-validation for RandomUnderSampler with DecisionTreeClassifier\n",
      "now cross-validating DecisionTreeClassifier with RandomOverSampler\n",
      "Finished cross-validation for RandomOverSampler with DecisionTreeClassifier\n",
      "now cross-validating DecisionTreeClassifier with SMOTE\n",
      "Finished cross-validation for SMOTE with DecisionTreeClassifier\n",
      "now cross-validating DecisionTreeClassifier with TomekLinks\n",
      "Finished cross-validation for TomekLinks with DecisionTreeClassifier\n",
      "now cross-validating DecisionTreeClassifier with SMOTETomek\n",
      "Finished cross-validation for SMOTETomek with DecisionTreeClassifier\n",
      "now cross-validating RandomForestClassifier with RandomUnderSampler\n",
      "Finished cross-validation for RandomUnderSampler with RandomForestClassifier\n",
      "now cross-validating RandomForestClassifier with RandomOverSampler\n",
      "Finished cross-validation for RandomOverSampler with RandomForestClassifier\n",
      "now cross-validating RandomForestClassifier with SMOTE\n",
      "Finished cross-validation for SMOTE with RandomForestClassifier\n",
      "now cross-validating RandomForestClassifier with TomekLinks\n",
      "Finished cross-validation for TomekLinks with RandomForestClassifier\n",
      "now cross-validating RandomForestClassifier with SMOTETomek\n",
      "Finished cross-validation for SMOTETomek with RandomForestClassifier\n",
      "                                           fit_time  score_time  \\\n",
      "model                  resampling_method                          \n",
      "LogisticRegression     RandomUnderSampler      0.52        0.26   \n",
      "                       RandomOverSampler       4.27        0.26   \n",
      "                       SMOTE                  12.28        0.25   \n",
      "                       TomekLinks             29.58        0.05   \n",
      "                       SMOTETomek            101.25        0.05   \n",
      "DecisionTreeClassifier RandomUnderSampler      0.62        0.26   \n",
      "                       RandomOverSampler       5.58        0.24   \n",
      "                       SMOTE                  13.25        0.30   \n",
      "                       TomekLinks             30.57        0.07   \n",
      "                       SMOTETomek             93.83        0.05   \n",
      "RandomForestClassifier RandomUnderSampler      7.09        8.52   \n",
      "                       RandomOverSampler     100.96        8.28   \n",
      "                       SMOTE                 132.58       11.14   \n",
      "                       TomekLinks             39.44        1.46   \n",
      "                       SMOTETomek            145.22        1.95   \n",
      "\n",
      "                                           test_accuracy  test_precision  \\\n",
      "model                  resampling_method                                   \n",
      "LogisticRegression     RandomUnderSampler           0.75            0.22   \n",
      "                       RandomOverSampler            0.75            0.22   \n",
      "                       SMOTE                        0.75            0.22   \n",
      "                       TomekLinks                   0.92            0.52   \n",
      "                       SMOTETomek                   0.75            0.22   \n",
      "DecisionTreeClassifier RandomUnderSampler           0.67            0.16   \n",
      "                       RandomOverSampler            0.87            0.22   \n",
      "                       SMOTE                        0.85            0.21   \n",
      "                       TomekLinks                   0.86            0.22   \n",
      "                       SMOTETomek                   0.85            0.21   \n",
      "RandomForestClassifier RandomUnderSampler           0.72            0.20   \n",
      "                       RandomOverSampler            0.89            0.31   \n",
      "                       SMOTE                        0.88            0.27   \n",
      "                       TomekLinks                   0.91            0.36   \n",
      "                       SMOTETomek                   0.90            0.31   \n",
      "\n",
      "                                           test_recall  test_f1  test_roc_auc  \n",
      "model                  resampling_method                                       \n",
      "LogisticRegression     RandomUnderSampler         0.78     0.35          0.84  \n",
      "                       RandomOverSampler          0.78     0.35          0.84  \n",
      "                       SMOTE                      0.78     0.35          0.84  \n",
      "                       TomekLinks                 0.14     0.22          0.84  \n",
      "                       SMOTETomek                 0.78     0.35          0.84  \n",
      "DecisionTreeClassifier RandomUnderSampler         0.66     0.26          0.67  \n",
      "                       RandomOverSampler          0.23     0.22          0.58  \n",
      "                       SMOTE                      0.29     0.24          0.59  \n",
      "                       TomekLinks                 0.28     0.25          0.59  \n",
      "                       SMOTETomek                 0.27     0.24          0.59  \n",
      "RandomForestClassifier RandomUnderSampler         0.77     0.32          0.81  \n",
      "                       RandomOverSampler          0.22     0.26          0.79  \n",
      "                       SMOTE                      0.24     0.25          0.79  \n",
      "                       TomekLinks                 0.13     0.19          0.80  \n",
      "                       SMOTETomek                 0.18     0.23          0.79  \n"
     ]
    }
   ],
   "source": [
    "final_score_table = cross_validate_diff_models_diff_data([LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier()], [rus, ros, smote, tl, smote_tl])\n",
    "print(final_score_table)\n",
    "final_score_table.to_csv('final_score_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the table above, we see the that \"test_recall\" and \"test_precision\" scores are worse than the scores obtained earlier. imblearn's pipeline automatically performs oversampling during cross validation.\n",
    "* The best performing combination is Logistic Regression with Random Undersampling. It achieves a recall of 0.78 and precision of 0.22.\n",
    "* Another observation is that the \"test_precision\" has gone down a lot across all undersampling and oversampling methods. We will try to address this issue in the next exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the models and results\n",
    "dill.dump_session('exploration_2.db')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9518128f597d7b00dc14729602cfd87fb7b2cf75925976bcb0d0e328a830a12b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
